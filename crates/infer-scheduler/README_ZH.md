# InferEngine 文档

InferEngine 是一个使用 Rust 构建的高性能、生产级大语言模型（LLM）推理引擎。其核心特性包括用于高效 KV 缓存利用的 **RadixAttention**、**高并发请求处理**以及用于优化内存管理的 **O(1) LRU 逐出算法**。

## 目录

- [概述](#概述)
- [设计理念](#设计理念)
- [系统架构](#系统架构)
- [核心组件](#核心组件)
- [数据流](#数据流)
- [API 参考](#api-参考)
- [快速入门](#快速入门)
- [高级主题](#高级主题)
- [性能调优](#性能调优)
- [故障排除](#故障排除)

---

## 概述

`infer-engine` crate 为大语言模型提供了一套完整的推理解决方案，具备以下关键特性：

- **RadixAttention**：前缀共享的 KV 缓存，通过在具有公共前缀的请求间复用已计算的 KV 值，最大限度地提高缓存命中率。
- **高并发**：细粒度锁设计支持多个请求并行处理。
- **O(1) LRU 逐出**：具有常数时间复杂度的快速缓存置换算法。
- **GPU 加速**：支持 CUDA，确保模型高效执行。
- **命名空间隔离**：支持多租户部署和 LoRA 适配器。
- **生产就绪**：完善的指标统计、错误处理和监控机制。

### 应用场景

- **聊天机器人与助手**：高效处理大量并发对话。
- **代码生成**：缓存通用的代码模式和模板代码（Boilerplate）。
- **文档分析**：处理内容重叠的多个文档。
- **多租户服务**：隔离不同的用户或组织。

---

## 设计理念

### 1. 通过细粒度锁实现最大吞吐量

引擎采用了精心设计的锁定策略以减少竞争：

| 资源 | 锁类型 | 并发性 |
| :--- | :--- | :--- |
| RadixCache | RwLock | 高 (N 个读取者) |
| KVCachePool | RwLock | 高 (N 个读取者) |
| Model (GPU) | Mutex | 串行 (1 个写入者) |
| Request Queue | Mutex | 短时占用 |
| Concurrency Limit | Semaphore | 资源限制 |

- **读多写少资源**：使用 `RwLock` 允许并发读取。
- **串行化资源**：当 GPU 执行必须串行时使用 `Mutex`。
- **短生存期锁**：尽可能快地释放锁。

### 2. 通过前缀共享提升缓存效率

RadixAttention 允许不同请求共享公共前缀的 KV 缓存：

```
请求 1: "The quick brown fox jumps over the lazy dog"
请求 2: "The quick brown fox jumps over the moon"
请求 3: "The quick brown fox runs fast"

共享前缀: "The quick brown fox" → 缓存一次，使用 3 次
```

这显著减少了以下场景的计算量：
- 在对话中重复使用的系统提示词（System Prompts）。
- 具有相同头文件的代码补全。
- 具有重叠章节的文档分析。

### 3. 生产就绪性

引擎专为生产环境部署而设计：

- **指标收集**：全面的耗时统计和缓存统计。
- **错误处理**：具备详细错误消息的优雅故障恢复。
- **监控支持**：内置可观测性的指标接口。
- **可配置限制**：有界队列、内存限制和并发控制。

### 4. 可扩展性

架构支持可插拔组件：

- **逐出策略**：支持 LRU、LFU、FIFO 或自定义策略。
- **内存池**：支持 CPU、CUDA 及自定义后端。
- **模型实现**：任何实现 `CacheAwareModel` 特性的模型均可接入。

---

## 系统架构

### 高层架构图

```
┌─────────────────────────────────────────────────────────────────────────┐
│                         ZMQ Server (ROUTER)                            │
│                                                                          │
│  ┌─────────────┐     ┌─────────────┐     ┌─────────────┐                │
│  │  接收器      │     │   发送器     │     │   监控      │                │
│  │  (线程)      │ --> │   (线程)     │     │   (异步)    │                │
│  └──────┬──────┘     └──────▲──────┘     └─────────────┘                │
│         │                   │                                            │
│         ▼                   │                                            │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │                     异步请求处理器 (Tokio)                        │    │
│  │  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐             │    │
│  │  │ 任务 1  │  │ 任务 2  │  │ 任务 3  │  │ 任务 N  │             │    │
│  │  └────┬────┘  └────┬────┘  └────┬────┘  └────┬────┘             │    │
│  │       └─────────────┴─────────────┴─────────────┘                │    │
│  │                          │                                       │    │
│  └──────────────────────────┼───────────────────────────────────────┘    │
│                             ▼                                            │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │                      InferenceEngine (推理引擎)                  │    │
│  │                                                                  │    │
│  │  ┌────────────────────┐    ┌────────────────────┐               │    │
│  │  │  SharedRadixCache  │    │  SharedKVCachePool │               │    │
│  │  │   (Arc<RwLock>)    │    │   (Arc<RwLock>)    │               │    │
│  │  └─────────┬──────────┘    └─────────┬──────────┘               │    │
│  │            │                          │                          │    │
│  │            │      缓存指令 (Instruction) |                          │    │
│  │            └──────────┬───────────────┘                          │    │
│  │                       ▼                                          │    │
│  │  ┌──────────────────────────────────────────────────────────┐  │    │
│  │  │  Model (Arc<Mutex<Llama3>>)                              │  │    │
│  │  │  - prefill_with_cache() (带缓存预填充)                    │  │    │
│  │  │  - decode_with_cache() (带缓存解码)                       │  │    │
│  │  └──────────────────────────────────────────────────────────┘  │    │
│  └─────────────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────────────┘
```

### Radix Cache (基数缓存) 架构

```
┌─────────────────────────────────────────────────────────────────────┐
│                         RadixCache                                   │
│  ┌────────────────────────────────────────────────────────────────┐ │
│  │                       基数树 (Radix Tree)                       │ │
│  │                                                                  │ │
│  │  [root] ─┬─ "The quick brown fox" (引用锁:3) ─┬─ " jumps"    │ │
│  │          │     [0,1,2,3,4,5,6,7,8,9,10,11,12]   │  → [13,14] │ │
│  │          │                                      └─ " runs"    │ │
│  │          │                                         → [13]     │ │
│  │          │                                                      │ │
│  │          └─ "Hello world" → [20,21,22,23,24,25,26]           │ │
│  │                                                                  │ │
│  │  操作: 匹配前缀, 插入, 节点拆分, 逐出                            │ │
│  └────────────────────────────────────────────────────────────────┘ │
│                              │                                       │
│                              │ Token 索引                            │
│                              ▼                                       │
│  ┌────────────────────────────────────────────────────────────────┐ │
│  │                    TokenToKVPool (内存池)                       │ │
│  │                                                                  │ │
│  │  K 缓存: [num_layers, max_tokens, kv_dim]                      │ │
│  │  V 缓存: [num_layers, max_tokens, kv_dim]                      │ │
│  │                                                                  │ │
│  │  空闲槽位: [100, 101, 102, 103, ...]                             │ │
│  └────────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────────┘
```

---

## 核心组件

### 1. InferenceEngine (`engine.rs`)

推理请求的主要调度器。

#### 关键特性
- **Token 信号量**：限制并发请求，防止资源耗尽。
- **多阶段处理**：将 Token 化、缓存准备、推理和完成阶段解耦。
- **并行批处理**：同时处理多个请求。
- **线程安全统计**：实时追踪请求指标。

#### 结构
```rust
pub struct InferenceEngine {
    model: Arc<Mutex<Llama3>>,              // 模型实例
    radix_cache: SharedRadixCache,           // 前缀共享缓存
    kv_pool: SharedKVPool,                   // KV 内存池
    request_queue: Arc<Mutex<VecDeque<...>>>, // 待处理队列
    concurrent_limit: Arc<Semaphore>,        // 并发控制
    config: EngineConfig,                    // 配置信息
    stats: Arc<RwLock<EngineStats>>,         // 指标统计
}
```

### 2. RadixCache (`kv_cache/`)

基于基数树的前缀共享缓存。

#### 关键特性
- **前缀共享**：多个请求对公共前缀共享缓存的 KV 值。
- **节点拆分**：针对部分匹配进行动态树结构重组。
- **引用锁定（Lock Propagation）**：锁定传播保护活跃前缀不被逐出。
- **O(1) 逐出**：通过 LRU 链表实现常数时间的缓存淘汰。

### 3. ZMQ Server (`zmq_server.rs`)

使用 ZMQ ROUTER 模式的高并发服务器。

#### 架构
- **专用 ZMQ 线程**：处理 I/O 操作。
- **每请求异步任务**：利用 tokio 实现真正的并行。
- **身份映射（Identity Mapping）**：将响应准确路由至对应客户端。

### 4. TokenToKVPool (`kv_cache/token_pool.rs`)

KV 缓存存储的内存池。

#### 特性
- **基于 Token 的分配**：灵活的内存管理。
- **CPU 与 CUDA 后端**：支持不同的存储介质。
- **空闲列表管理**：高效复用已释放的槽位。

---

## 数据流

### 请求完整生命周期

1. **请求到达 (ZMQ)**
2. **创建推理请求 (协议解析)**
3. **入队 (Mutex<VecDeque>)**
4. **处理请求 (并行执行)**
    - **阶段 1: Token 化** (获取模型锁 -> 编码 -> 释放锁)
    - **阶段 2: 缓存准备** (在 RadixCache 中匹配前缀 -> 分配新槽位 -> 锁定前缀)
    - **阶段 3: Prefill (预填充) 推理** (获取模型和 KV 池锁 -> 推理 -> 获取首个 Token)
    - **阶段 4: Decode (解码) 循环** (循环生成 Token -> 检查停止条件 -> 分配缓存槽位 -> 执行解码)
    - **阶段 5: 缓存完成** (将新 Token 插入缓存 -> 解锁前缀 -> 释放所有锁)
    - **阶段 6: 响应** (Token 转文本 -> 构建响应体 -> 通过 ZMQ 发送)
5. **客户端接收响应**

---

## API 参考

### 引擎 API

#### 创建引擎
```rust
use infer_engine::{InferenceEngine, EngineConfig};

let config = EngineConfig {
    max_batch_size: 32,
    max_queue_size: 256,
    schedule_interval_ms: 1,
    max_concurrent_requests: 64,
    max_cache_tokens: 65536,
    num_layers: 28,
    kv_dim: 256,
};

let engine = InferenceEngine::new(model, config)?;
```

#### 获取统计数据
```rust
let stats = engine.engine_stats().await;
println!(
    "总请求数: {}, 已完成: {}, 命中率: {:.1}%",
    stats.total_requests,
    stats.completed_requests,
    stats.cache_hits as f64 / (stats.cache_hits + stats.cache_misses) as f64 * 100.0
);
```

### 缓存 API

#### 使用命名空间 (Namespace)
```rust
// 创建具有命名空间隔离的缓存条目
let key1 = RadixKey::with_namespace(vec![1, 2, 3], "tenant-1".to_string());
let key2 = RadixKey::with_namespace(vec![1, 2, 3], "tenant-2".to_string());

// 即使 Token 相同，它们也不会共享缓存
```

---

## 性能调优

### 配置参数指南

| 参数 | 描述 | 默认值 | 调优建议 |
| :--- | :--- | :--- | :--- |
| `max_concurrent_requests` | 最大并发请求数 | 64 | GPU 利用率低则调大，OOM 则调小 |
| `max_batch_size` | 并行处理批大小 | 32 | 需适配 GPU 显存限制 |
| `max_cache_tokens` | KV 缓存容量 | 65536 | 越大命中率越高，但显存占用增加 |
| `schedule_interval_ms` | 队列处理间隔 | 1 | 越小延迟越低，但 CPU 占用增加 |

### 显存计算

估计显存占用：
`KV 缓存大小 = max_cache_tokens × num_layers × kv_head × head_dim × 2 (K/V) × dtype_size`

此外还需加上模型权重（7B bf16模型通常为 14 GB）。

---

## 故障排除

### 常见问题

- **显存溢出 (OOM)**: 
    - 减小 `max_cache_tokens`。
    - 减小 `max_concurrent_requests`。
- **高延迟**: 
    - 检查 `avg_queue_time_ms`（排队时间）。如果高，增加并发数。
    - 如果预填充/解码慢，说明达到了 GPU 算力瓶颈。
- **低缓存命中率**: 
    - 确保使用了统一的系统提示词。
    - 检查是否在不需要的地方使用了不同的 `namespace`。

---

## 术语表

- **KV Cache**: 键值缓存，存储每个 Token 位置的注意力机制 Key 和 Value。
- **RadixAttention**: 使用基数树数据结构实现的前缀共享 KV 缓存技术。
- **Prefill (预填充)**: 处理提示词 Token 并计算其 KV 值的过程。
- **Decode (解码)**: 逐个生成 Token 并将其追加到缓存的过程。
- **Lock Propagation (锁定传播)**: 一种引用计数机制，用于保护基数树中的祖先节点不被逐出。

---

## 贡献

在扩展本引擎时，请遵循以下原则：
1. **保持线程安全**：使用适当的锁和 Arc 封装。
2. **减少锁竞争**：尽早释放锁。
3. **完善指标**：在 `EngineStats` 中记录新操作。
4. **编写测试**：覆盖并发访问模式。

---

## 许可证

本项目是 RustInfer 项目的一部分。详见 LICENSE 文件。